# Procesamiento del Lenguaje natural
Este repositorio contiene el material de clases (presentaciones, ejercicios y notebooks) para NLP (CEIA - FIUBA)

## Contenido

### [Clase 1](clase_1/README.md) 
* Introducción a NLP (Natural Language Processing)
* Vectorización de documentos

### [Clase 2](clase_2/README.md)
* Preprocesamiento de texto
* Librerías de preprocesamiento para NLP
* Information-retrieval bots

### [Clase 3](clase_3/README.md)
* Word embeddings, CBOW y SkipGRAM
* Representación de palabras

### [Clase 4](clase_4/README.md)
* Redes recurrentes (RNN)
* Problemas de secuencia
* Estimación de próxima palabra

### [Clase 5](clase_5/README.md)
* Redes LSTM
* Análisis de sentimiento (sentiment analysis)
    
### [Clase 6](clase_6/README.md)
* Modelos Seq2Seq
* Bots conversacionales y traductores

### [Clase 7](clase_7/README.md)
* Celdas con Attention
* Transformers
* BERT y ELMo
* Fine tuning

### [Clase 8](clase_8/README.md)
* Cierre del curso
* Deployment de servicio NLP
* Flask, APIs
* Docker y Tensorflow Serving (TFX)

# Profesores
:octocat: Dr. Rodrigo Cardenas Szigety\
:octocat: Esp. Ing. Hernán Contigiani

Procesamiento Natural del Lenguaje
CONTENIDO: El repositorio contiene 6 desafios que fuimos realizando a lo largo del bimestre.
Desafio 1: Word2vec
El objetivo es empezar a familiarizarse con el manejo de terminos y herramientas del Procesamiento Natural del Lenguaje.
Desafio 2: BOT dnn spacy español
Bot en español utilizando spacy stanza para la venta de un productos
Desafio 3: Embedding con Gemsim
El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizo un corpus de las 50 canciones mas populares del rock argentino en un ranking presentado por la revista Rolling Stone en colaboración con la cadena MTV.
Desafio 4: Predicción de próxima palabra
El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto utilizando la layer Embedding de Keras. Se utilizará esos embeddings junto con layers LSTM para predeccir la próxima posible palabra. Se utilizo el corpus del libre "Papeles en el viento" de Eduardo Sacheri. El modelo es LSTM junto con una primer capa de embedding.
Desafio 5: Analisis de sentimientos
El dataset utilizado es de críticas de compradores de ropa (eCommerce) los cuales puntuaron a cada prenda con un puntaje de 1 a 5 estrellas. Las etapas incluyen:
Con el dataset sin balancear
Desafio 6: QA Bot
El objecto es utilizar datos disponibles de convai de conversaciones en ingleś. Se construirá un BOT para responder a preguntas del usuario (QA). El modelo es del tipo encoder - decoder.
